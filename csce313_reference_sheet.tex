% Josh_Wright_Resume.tex
% (c) Copyright 2015 Josh Wright
\documentclass[12pt]{article}
\usepackage{verbatim}
% \usepackage{syntonly}
\usepackage{ragged2e}
\usepackage{geometry}
\usepackage{enumitem} % for longenum
\usepackage{setspace}
\usepackage{hyperref}
\usepackage{setspace}
\usepackage{tabularx}
\usepackage{outlines} % for outline
\usepackage{paralist} % for compactitem (compact itemize)
\usepackage{multicol} % for multicolumn layout
\geometry{letterpaper, margin=0.25in, top=0.1in}
% \geometry{letterpaper, margin=0.5in, top=0.35in, left=1.5in}

\begin{document}
\begin{spacing}{0.6}
% \begin{center}
% CSCE313 Refsheet
% \hfill \textcopyright \space Josh Wright 2015 \hfill
% Last Updated: \today
% \vspace{-12px}
% \end{center}


%%%%%%%%%%%%%%%%%%
%% main section %%
%%%%%%%%%%%%%%%%%%
\begin{multicols*}{2}
\begin{flushleft}
\newlist{longenum}{itemize}{5}
\setlist[longenum,1]{nosep,leftmargin=0.2cm,labelwidth=0px,align=left,label=$\bullet$}
\setlist[longenum,2]{nosep,leftmargin=0.2cm,labelwidth=0px,align=left,label=$\ast$}
\setlist[longenum,3]{nosep,leftmargin=0.2cm,labelwidth=0px,align=left,label=-}
\setlist[longenum,4]{nosep,leftmargin=0.2cm,labelwidth=0px,align=left,label=>}
\setlist[longenum,5]{nosep,leftmargin=0.2cm,labelwidth=0px,align=left,label=@}
\begin{outline}[longenum]
\newcommand{\zzz}[1]{\0 \textbf{#1} }

\small
% \footnotesize

CSCE313 Refsheet; 
\textcopyright \space Josh Wright 2015;
Last Updated: \today


% \zzz{OS}
%   \1 \textbf{referee:} manages shared resources, protects programs from each other
%   \1 \textbf{illusionist:} infinite memory, dedicated machine
%   \1 \textbf{glue:} (common services) storage, window system, networking, authorization
%   \1 goals: reliability, availability, security, privacy, portability, performance
%   \1 \textbf{DMA:} Direct Memory Access
%     \2 allow a peripheral to do it's work, then put the result directly in RAM
%     \2 generates IO interrupt when finished
%     \2 allows schedulers to overlay IO access with CPU bursts

\zzz{Batch OS}
  \1 jobs are submitted in batches
  \1 just used DMA for IO
  \1 basically FIFO, but with using DMA for loading P2 while P1 is still running

\zzz{Time Sharing OS}
  \1 CPU cycles through jobs in defined order
  \1 basically round robin

\zzz{Exception Control Flow}
  \1 exception: transfer of control from the user program to the OS in response to an event
  \1 event: interrupt or system call or something
  \1 CPU checks for interrupts before every instruction
    % \2 if there are multiple interrupts in the queue, it will handle them all in order before resuming what it was doing
  \1 \textbf{Asynchronous Exception}: caused by something external to the processor. (e.g. not a system call)
    \2 e.g. IO interrupts, hard/soft reset
  \1 \textbf{Interrupt Vector Table:} stored in CPU, has function pointers at indexes identified by interrupt codes
    \2 one slot for every possible type of interrupt
    \2 first thing handler does is disable interrupts, then re-enable when done
  \1 \textbf{Synchronous exceptions:} caused by executing an instruction (internal to CPU)
    \2 Trap: intentional; system calls, breakpoints
      \3 returns code to next userland instruction
    \2 Faults: unintentional. maybe recoverable; generally retry or abort.
      e.g. page fault, floating point exception
      % \3 Page Fault: 
      %   trying to use a page that hasn't been allocated by the kernel yet;
      %   will retry the failing instruction
      % \3 Floating-Point Exception (divide by 0)
    \2 Abort: unintentional; unrecoverable
      % \3 e.g. pairity error
  \1 RTU: Return To User

% \zzz{Architectural Features:}
% \\ Protection Modes, Interrupts/exceptions, System Calls, Timers, Memory Protection Mechanisms, Synchronization Primitives

\zzz{Dual Mode}
  \1 CPU supports two modes: kernel mode and user mode
    \2 keeps a flag register depending on current mode
  \1 user mode is disallowed some dangerous instructions and only allowed it's mapped memory regions
  \1 kernel mode gets full control over everything
  \1 must switch between the two, which has overhead
  \1 Memory Protection: uses MMU hardware
    \2 kernel has no memory protection
  \1 hardware timer: fires interrupts at predefined intervals
    \2 kernel will set timed interrupts to switch control back to the kernel from the user program periodically
    % \2 this is the basis of the scheduler
    \2 setting/clearing timers is a privileged instruction
  \1 user$\rightarrow$kernel: on interrupt, syscall
  \1 kernel$\rightarrow$user: end of interrupt handler, or at proc start
  % \1 user$\rightarrow$kernel context switch:
  %   \2 triggered by one of: interrupt, fault, whatever
  %   \2 kernel backs up userland sate before doing things. (registers, instruction pointers, stuff)
  %   \2 if it's a system call, kernel reads it's arguments from registers
  % \1 kernel$\rightarrow$user
  %   \2 happens when: starting a new process; returning from synchronous interrupt; scheduling
  %   \2 restores userland state

\zzz{Unix Processes}
  \1 process: instance of running program
  \1 has it's own private address space 
    % (provided by illusionist kernel)
    % \2 for 32bit, it's 4GB large. There isn't really 4GB physical memory per process, due to virtual memory (it's an illusion)
  % \1 Logical Control Flow: process doesn't notice that it's being scheduled in and out (illusion)
  \1 Zombie Process: when a child process exits, the kernel must keep it's memory around just in case the parent needs to know if it exited cleanly
    \2 this child process is a zombie process.
    \2 call \verb|wait()| to avoid this
    \2 reaping is the process of killing zombies

% \zzz{Shell}
%   \1 is not the kernel; does IO redirection
%   \1 to run a subcommand, \verb|fork()|s and then \verb|execv()|s
%   \1 \verb|fork()|: clone process. One is parent, one is child
%     \2 child must be kept around until parent either calls wait() or until the parent terminates
%   \1 \verb|execv()|: replaces running program image.
%     \2 you can specify arguments and environment
%     \2 does not return, unless there is an error

% \zzz{Pipes}
%   \1 made with \verb|pipe()| or \verb|pipe2()|
%   \1 a set of 2 file descriptors
%   \1 has a write end and a read end
%   \1 used for Inter Process Communication (IPC)
%   \1 persists across \verb|fork()|

\zzz{Process Lifetime/States}
  \1 all this stuff looks like continuous running to the process
  \1 \textbf{Ready:} scheduled to be run
  \1 \textbf{Running:} currently running
  \1 \textbf{Blocked:} waiting on something. (IO or other wait)
  \1 transitions:
    \2 newly created processes go to ready; after exit, leaves running position
    \2 ready$\rightarrow$running: dispatch
    \2 running$\rightarrow$ready: preempt
      \3 also happens when scheduling timer expires
    \2 running$\rightarrow$blocked: triggers IO event or wait
    \2 blocked$\rightarrow$ready: IO event or wait finishes
  \1 only one process is in running state per CPU core
    % \2 (and while a user process is running, the kernel isn't)
  \1 Additional states: (managed by memory scheduler)
    \2 Suspended Ready: ready to run, but swapped out of main memory due to memory constraints.
      ; get here from start or ready
      ; leave to ready when ready
    \2 Suspended Blocked: swapped out of main memory, and also waiting on some external event
      ; get here from blocked
      ; leave to suspended ready or blocked
  \1 \textbf{Process Control Block} (PCB)
    % \2 how the kernel keeps track of process
    \2 contains process id, state, saved registers, memory maps, child processes, owned resources, file descriptors
    \2 whenever a context switch happens, the previous process state is stored in and restored from the PCB
  \1 Job Queue: set of all processes in a system
  \1 Ready Queue: in main memory, waiting to be run
  \1 Device Queues: waiting for IO by device

\zzz{Scheduling}
  \1 Latency: how long it takes for the job to complete
  \1 Throughput: \# of jobs can be completed per unit time
  \1 Overhead: how much work the scheduler must do
  \1 Fairness: do different users/process types/other factors influence scheduling priority?
  \1 Predictability: also consistency
  \1 Preemptive Scheduler: one that takes control away from a process (usually through timed interrupts)
  \1 Work Conserving: never leave a CPU idle
    % \2 We only consider preemptive, work conserving schedulers
  \1 Time Quantum: length of scheduler interrupt timer
  \1 Waiting Time: time spend in not running
    % \2 includes waiting on execution (in ready queue) and total time spent in all waiting queues
  \1 Service (Execution) Time: how long the job is running
  \1 Response (Completion) Time: wall clock time process takes
    ; response = waiting + ready
  % \1 Possible scheduling goals
  %   \2 minimum response time (latency); maximum throughput; fairness
  \1 Long-Term Scheduler: (Job Scheduler)
    \2 selects which job to brought into the ready queue
    \2 should select a good mix of CPU and IO bound processes
  \2 Short-Term Scheduler: (CPU Scheduler)
    \2 selects what to run from the ready queue
    \2 runs every time quantum, so it shall be fast
  \1 Medium-Time Scheduler: swaps out programs from main memory (suspends them)
  \1 First In First Out (FIFO), or FCFS:
    \2 works well on one really long task with many small tasks, if the long task comes first (e.g. servers)
  \1 \textbf{Shortest Remaining Time First:} (SRTF) (or Shortest Job First (SJF))
    \2 the ideal scheduler in most cases
      \3 advantage best for average response time
      \3 disadvantage: longer tasks can get starved
      \3 disadvantage: high variance on average response time
    \2 not really possible because we can't know how long a job will take ahead of time
      \3 can be approximated by guessing the next CPU burst
    \2 if all tasks are the same length, runs them all in order, no preemption
    \2 shortest task starts and finishes first
  \1 \textbf{Round Robin:}
    \2 each task gets run for one time quantum
      \3 choice of time quantum is critical
    \2 compromise between SJF and FIFO
    \2 always fair
    \2 time quantum too small: too much overhead
    \2 time quantum approaches $\infty$: equivalent to FIFO
  \1 \textbf{Multi-Level Feedback Scheduling:}
    \2 have multiple ready queues
      \3 sub-queue are prioritized
    \2 processes start in highest priority queue, then are moved to lower queue after using CPU too much
      % \3 means that IO bound processes get higher CPU priority  (other things to fix this)
    \2 must schedule between queues:
      \3 fixed priority: highest priority, then lower (not fair)
      \3 time slicing: fixed percentage of time to each queue.
    \2 approximates SRTF: CPU-bound suffers, lets IO bound stay near top
  % \1 Countermeasure: something a process does to fool the scheduler into giving it a higher priority
    \2 example: putting in superfluous IO waits 
  \1utilization approaches 100\%, latency and throughput suffer





\end{outline}
\end{flushleft}
\end{multicols*}
\end{spacing}
\end{document}
